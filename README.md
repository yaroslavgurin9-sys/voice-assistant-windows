# Voice Assistant for Windows 11

AI-powered voice assistant for Windows 11 with offline speech recognition, intelligent routing, and local LLM integration. Similar to Alexa/Siri but fully free, private and customizable.

## Features

âœ¨ **Core Capabilities**
- ğŸ¤ Offline speech recognition (STT) via Vosk
- ğŸ”Š Text-to-speech synthesis in Russian (pyttsx3)
- ğŸ¯ Wake word detection ("ĞÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚", "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚", etc.)
- âš¡ Sub-1 second response time with local processing
- ğŸ§  AI chat integration (local Ollama or cloud API)
- ğŸŒ Web browser automation
- ğŸ“± Application launcher with custom aliases
- ğŸ‘ï¸ Screen analysis with OCR (Tesseract)
- âŒ¨ï¸ Mouse and keyboard automation

## Quick Start

### Prerequisites
- Windows 11 with Python 3.10+
- Microphone
- Internet (for initial setup only)

### Installation

```bash
# Clone repository
git clone https://github.com/yaroslavgurin9-sys/voice-assistant-windows.git
cd voice-assistant-windows

# Create virtual environment
python -m venv venv
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Setup

**1. Download Vosk Model**
```bash
# Download Russian model from https://alphacephei.com/vosk/models
# Extract to: models/vosk_models/model-ru/
```

**2. Install Tesseract OCR**
- Download from: https://github.com/UB-Mannheim/tesseract/wiki
- Install to: `C:\Program Files\Tesseract-OCR\`
- Select Russian language during installation

**3. Setup LLM (Choose one)**

Option A: Ollama (Recommended)
```bash
# Download from https://ollama.ai/
# Run: ollama run neural-chat
```

Option B: LM Studio
- Download from https://lmstudio.ai/
- Start server at localhost:1234

### Run

```bash
# Console mode
python main.py

# Or with batch file
run.bat
```

Say: **"ĞÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚"** to activate, then give commands.

## Usage Examples

```
"ĞÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚" â†’ Activates assistant
"ĞÑ‚ĞºÑ€Ğ¾Ğ¹ Chrome" â†’ Launches Google Chrome
"ĞÑ‚ĞºÑ€Ğ¾Ğ¹ YouTube" â†’ Opens youtube.com
"ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ¹ Ñ‡Ñ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¾" â†’ OCR text from active window
"Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Python?" â†’ AI answers question
"Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸ PyCharm" â†’ Launches IDE
"Ğ—Ğ°ĞºÑ€Ğ¾Ğ¹ ÑÑ‚Ğ¾ Ğ¾ĞºĞ½Ğ¾" â†’ Closes active window
```

## Project Structure

```
voice-assistant/
â”œâ”€â”€ core/                          # Main modules
â”‚   â”œâ”€â”€ audio_input.py            # Microphone capture
â”‚   â”œâ”€â”€ wake_word.py              # Wake word detection
â”‚   â”œâ”€â”€ stt_engine.py             # Speech recognition
â”‚   â”œâ”€â”€ tts_engine.py             # Text-to-speech
â”‚   â”œâ”€â”€ command_router.py         # Command routing
â”‚   â”œâ”€â”€ system_controller.py      # App/system control
â”‚   â”œâ”€â”€ screen_analyzer.py        # OCR and screenshots
â”‚   â”œâ”€â”€ ai_chat.py                # LLM integration
â”‚   â””â”€â”€ logger.py                 # Logging
â”‚
â”œâ”€â”€ config/                        # Configuration
â”‚   â”œâ”€â”€ settings.py               # Main settings
â”‚   â”œâ”€â”€ commands.json             # Command mapping
â”‚   â”œâ”€â”€ apps_registry.json        # App paths
â”‚   â”œâ”€â”€ aliases.json              # Command aliases
â”‚   â””â”€â”€ system_prompt.txt         # LLM system prompt
â”‚
â”œâ”€â”€ models/                        # Models and data
â”‚   â”œâ”€â”€ vosk_models/
â”‚   â”‚   â””â”€â”€ model-ru/
â”‚   â””â”€â”€ prompts/
â”‚
â”œâ”€â”€ ui/                            # GUI (Optional)
â”‚   â”œâ”€â”€ gui_main.py
â”‚   â””â”€â”€ gui_threads.py
â”‚
â”œâ”€â”€ logs/                          # Application logs
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ main.py                        # Entry point
â”œâ”€â”€ run.bat                        # Quick launcher
â””â”€â”€ README.md
```

## Configuration

### config/settings.py

```python
# Audio configuration
config.audio.SAMPLE_RATE = 16000
config.audio.CHUNK_SIZE = 4096

# Vosk STT
config.vosk.MODEL_PATH = "models/vosk_models/model-ru"
config.vosk.TIMEOUT_SECONDS = 30.0

# TTS
config.tts.RATE = 150  # Words per minute
config.tts.VOLUME = 0.9

# Wake words
config.wake_word.WAKE_WORDS = ["Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚", "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚", "Ğ¾ĞºĞµĞ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚"]

# AI Settings
config.ai.USE_LOCAL_MODEL = True
config.ai.LOCAL_MODEL_TYPE = "ollama"
config.ai.OLLAMA_MODEL = "neural-chat"
config.ai.OLLAMA_API_URL = "http://localhost:11434/api/generate"
```

### Custom Commands

Edit `config/commands.json` to add command mappings:

```json
{
  "app_launcher": {
    "keywords": ["Ğ¾Ñ‚ĞºÑ€Ğ¾Ğ¹", "Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸"],
    "apps": [
      {"name": "chrome", "aliases": ["Ñ…Ñ€Ğ¾Ğ¼", "Ğ±Ñ€Ğ°ÑƒĞ·ĞµÑ€"]}
    ]
  }
}
```

## Architecture

```
Audio Input (Microphone)
        â†“
Wake Word Detector ("ĞÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚")
        â†“
Speech Recognition (Vosk STT)
        â†“
Command Router (Pattern Matching)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                â”‚             â”‚
â–¼                â–¼             â–¼
System          Screen        AI Chat
Controller      Analyzer      Module
(Apps/Web)      (OCR/Click)    (LLM)
        â”‚                â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        Text-to-Speech (pyttsx3)
                 â”‚
                 â–¼
        Speaker/Audio Output
```

## Technology Stack

| Component | Technology | Notes |
|-----------|-----------|-------|
| STT | Vosk | Offline, Russian support |
| TTS | pyttsx3 | Offline, local voices |
| LLM | Ollama/LM Studio | Local or cloud API |
| OCR | Tesseract | Open source |
| Audio | sounddevice | Cross-platform |
| Automation | pyautogui | Screen/keyboard control |
| GUI | PyQt6 | Optional |
| Framework | Python 3.10+ | Async/threading |

## Troubleshooting

### Vosk model not found
```
â†’ Download from https://alphacephei.com/vosk/models
â†’ Extract model-ru to models/vosk_models/model-ru/
```

### PyAudio won't install
```bash
pip install pipwin
pipwin install pyaudio
```

### Microphone not working
```python
import sounddevice as sd
print(sd.query_devices())  # Find your device index
# Update config.audio.MIC_DEVICE_INDEX
```

### LLM not responding
- Check Ollama is running: `ollama run neural-chat`
- Verify API at http://localhost:11434/api/tags
- Check config.ai.OLLAMA_API_URL

### Tesseract not found
```
â†’ Install to C:\Program Files\Tesseract-OCR\
â†’ Update config.screen.TESSERACT_PATH
```

## Performance Optimization

- **Wake word detection**: Always-on, low CPU usage
- **STT latency**: <500ms with local Vosk
- **Command execution**: Threaded to avoid blocking
- **LLM response**: Async streaming for smooth UX
- **Logging**: Async file I/O

## Security & Privacy

âœ… All processing is local (no cloud required)
âœ… No data sent to external services by default
âœ… Custom LLM models can be run completely offline
âœ… Supports encrypted API keys for optional cloud services

## Extending

### Add New Command

```python
# In core/command_router.py
def _handle_custom_action(self, text: str) -> str:
    if 'take screenshot' in text:
        self.screen_analyzer.take_screenshot('screenshot.png')
        return "Screenshot saved"
    return "Unknown command"
```

### Add Application

Edit `config/apps_registry.json`:
```json
{
  "telegram": "C:\\Users\\Name\\AppData\\Local\\Telegram\\Telegram.exe"
}
```

### Add Wake Word

Edit `config/settings.py`:
```python
config.wake_word.WAKE_WORDS = [
    "Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚",
    "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚",
    "Ğ¾ĞºĞµĞ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚",
    "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚",  # New wake word
]
```

## Logging

Logs are saved to `logs/assistant.log` with:
- Timestamp
- Recognized text
- Command type
- Execution result

```python
from core.logger import app_logger
app_logger.info("Custom message")
```

## Advanced Usage

### Remote API Integration

```python
# Use cloud API instead of local LLM
config.ai.USE_LOCAL_MODEL = False
config.ai.USE_CLOUD_API = True
config.ai.CLOUD_API_TYPE = "openai"
config.ai.CLOUD_API_KEY = "sk-..."
```

### Multiple LLM Models

```python
# Switch between models
config.ai.OLLAMA_MODEL = "mistral"  # Fast
config.ai.OLLAMA_MODEL = "neural-chat"  # Better quality
```

### Enable GUI

```python
# In main.py
assistant = VoiceAssistant(enable_gui=True)
assistant.start()
```

## Contributing

Feel free to fork, modify, and submit pull requests!

## License

MIT License - Free for personal and commercial use

## Author

Created as a comprehensive voice assistant framework for Windows 11.

## Support

For issues, questions, or suggestions:
1. Check existing issues on GitHub
2. Review logs in `logs/assistant.log`
3. Open a new issue with:
   - Windows version
   - Python version
   - Error logs
   - Reproduction steps

## Roadmap

- [ ] GUI dashboard with command history
- [ ] Global hotkeys for quick access
- [ ] Multi-language support (English, Spanish, etc.)
- [ ] Skill plugins system
- [ ] Database for persistent context
- [ ] Integration with weather/news APIs
- [ ] Desktop notifications
- [ ] Command scheduling
- [ ] Voice recording and playback
- [ ] Advanced NLP for better intent detection

---

**Status**: Active Development
**Last Updated**: February 2026
**Python**: 3.10+
**OS**: Windows 11
